Постановка задачи:

Построить рекомендательную модель, обучить используя  представленный дата-сет и вывести топ 10 рекомендации фильмов, которые пользователь еще не видел. Нужно так же учитывать название фильмов при рекомендации. 
Решение предоставить в виде python скрипта/ов или jupyter notebooks (построение модели или использование существующей, обучение и вывод топ 10 рекомендации для пользователя)
Так же в качестве решения рассмотрим текстовое описание подхода к решению. Описание должно содержать описание алгоритмов, список используемых технологий и инструментов и принцип работы. Так же необходимо аргументировать свой выбор.

Описание репозитория: 

1) movies.csv и ratings.csv - использованные части исходного датасета.
2) Тестовое задание(Бондаренко Д.П.).ipynb - jupyter notebook, в котором проверялись основные подходы к построению рекомендательных систем.
3) Классы.ipynb - jupyter notebook, содержащий в себе финальные алгоритмы, обернутые в классы с методами fit(), predict(), а так же уникальными методами для некоторых классов. 

Ход работы: 

Было решено реализовать 3 принципиально различных подхода: Collaborative filtering, Content based filtering, Popularity based filtering.
У первых двух подходов есть проблема холодного старта, поэтому, очевидно, что для новых пользователей вклад Popularity based filtering должен быть больше, чем у других двух подходов, которые проявляют себя хорошо, пир наличии большого количества данных о пользователе. 

Collaborative filtering

1) Первым делом, было решено выявить baseline, тоесть создать наивный алгоритм, точность которого, в последствии, мы будем улучшать. Таким решением было предсказывать среднюю оценку по каждому фильму. 
2) Первым испобованым алгоритмом был поиск наиболее похожих пользователей. Была создана матрица user X item, зполненная рейтингами, которые поставил iтый юзер jтому фильму. Затем было подсчитано косинусное расстояние между векторами каждого юзера, аналогично для итемов. Была исследована зависимость точности от количества учтенных наиболее похожих юзеров/итемов.
3) Второй алгоритм предсказывыал рейтинг, основывавыясь на среднем рейтинге конкретного пользователя, а так же на среднем рейтинге похожих пользователей. Сам алгоритм крайне похож на предыдущий, однако, по сути, теперь мы предсказываем отклонение человека от его средней оценки, что сильно помогло увеличить точность алгоритма. 
4) Третьим алгоритмом было Сингулярное разложение матрицы или SVD. Данное разложение представляет матрицу как произведение трех матриц U, s, V меньшей размерности.
Где U - ортогональная левая сингулярная матрица, которая описывает взаимосвязь между пользователями и неявными факторами, S - диагональная матрица, которая описывает вес каждого неявного фактора, а V - это диагональная правая сингулярная матрица, которая указывает на сходство между элементами и невными факторами.
Так же была взята реализация этого метода из бибилиотеки surprise. Это библиотека, содержащая все методы калоборативной фильтрации, а так же вспомогательные методы для выбора гиперпараметров методов и т.д.

 Content based filtering

Этот подход основан на векторизации всех итемов. В данном случае было решено воспользоваться с помощью TF-IDF векторизации векторизовать названия фильмов. Далее вычисляется вектор юзера и находится наиболее близкие к нему вектора итемов.

 Popularity based filtering
 
 Это самый очевидный подход, он рекомендует каждому пользователю самые популярные фильмы. Для его реализации было необходимо лишь  вычислить вес каждого фильма и рекомендовать самые популярные. 
